{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[211]:\n",
    "\n",
    "\n",
    "\"\"\" Basic example showing samples from the dataset with bounding boxes and 2 hands\"\"\"\n",
    "\n",
    "from __future__ import print_function, unicode_literals\n",
    "import PIL\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# chose between training and evaluation set\n",
    "set = 'training'\n",
    "#set = 'evaluation'\n",
    "\n",
    "# load annotations of this set\n",
    "with open(os.path.join(set, 'anno_%s.pickle' % set), 'rb') as fi:\n",
    "    anno_all = pickle.load(fi)\n",
    "images_cropped = []\n",
    "\n",
    "#Example for 10 images\n",
    "for sample_id in range(len(anno_all)):\n",
    "    one_hand = False\n",
    "    anno = anno_all[sample_id]\n",
    "    image = scipy.misc.imread(os.path.join(set, 'color', '%.5d.png' % sample_id))\n",
    "\n",
    "    # get info from annotation dictionary\n",
    "    kp_coord_uv = anno['uv_vis'][:, :2]  # u, v coordinates of 42 hand keypoints, pixel\n",
    "    kp_visible = (anno['uv_vis'][:, 2] == 1)  # visibility of the keypoints, boolean\n",
    "\n",
    "    # Visualize data\n",
    "    #fig = plt.figure(figsize=(25,25))\n",
    "    #ax1 = fig.add_subplot('221')\n",
    "    #ax1.imshow(image)\n",
    "    #ax1.plot(kp_coord_uv[kp_visible, 0], kp_coord_uv[kp_visible, 1], 'ro')\n",
    "    \n",
    "    #keypoints of hand1\n",
    "    hand1 = kp_coord_uv[:21]\n",
    "    hand1v = kp_visible[:21]\n",
    "    hand2 = kp_coord_uv[21:]\n",
    "    hand2v = kp_visible[21:]\n",
    "    \n",
    "    if(len(hand1[hand1v,0]) <= (len(hand2[hand2v,0]))):\n",
    "        one_hand = True\n",
    "        hand1 = hand2\n",
    "        hand1v = hand2v\n",
    "\n",
    "    #bounding box edges\n",
    "    x1,y1 = max(hand1[hand1v,0]), max(hand1[hand1v,1])\n",
    "    x2,y2 = min(hand1[hand1v,0]), min(hand1[hand1v,1])\n",
    "    \n",
    "    #unpadded width and height\n",
    "    w = abs(x1-x2)\n",
    "    h = abs(y1-y2)\n",
    "    \n",
    "    #padding 10% hand 1 (Keypoints lie IN the hand -> Bounding box needs padding to cover whole hand)\n",
    "    pad_x1 =x1+ 0.1 * w\n",
    "    pad_y1 =y1+ 0.1 * h\n",
    "    pad_x2 =max(0,(x2 - 0.1 * w))\n",
    "    pad_y2 =max(0,(y2 - 0.1 * h))\n",
    "\n",
    "\n",
    "    #bbox width and height\n",
    "    w = abs(pad_x1-pad_x2)\n",
    "    h = abs(pad_y1-pad_y2)\n",
    "    \n",
    "    if h < w:\n",
    "        h = w\n",
    "    else:\n",
    "        w = h\n",
    "    if(w>0):\n",
    "        if one_hand:\n",
    "            cropped_image = image[int(round(pad_y2)):int(round(pad_y2))+int(round(h)) , int(round(pad_x2)):int(round(pad_x2))+int(round(w)), :]\n",
    "        else:\n",
    "            cropped_image = image[int(round(pad_y2)):int(round(pad_y2))+int(round(h)) , int(round(pad_x2)):int(round(pad_x2))+int(round(w)), :]\n",
    "       # ax1.imshow(image[int(round(pad_y2)):int(round(pad_y2))+int(round(h)) , int(round(pad_x2)):int(round(pad_x2))+int(round(w)), :])\n",
    "        #print(cropped_image.shape)\n",
    "        cropped_image = PIL.Image.fromarray(cropped_image)\n",
    "        images_cropped.append([image])\n",
    "    #plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataF = pd.DataFrame((images_cropped))\n",
    "dataF.to_csv(path_or_buf=\"dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
